{
  "name": "token-shrinker",
  "version": "1.6.3",
  "description": "Model Context Protocol (MCP) server for compressing AI context to reduce token usage. Provides tools to shrink text, summarize files, and cache repository content.",
  "type": "module",
  "main": "src/mcp-server.js",
  "bin": {
    "token-shrinker": "./bin/cli.js"
  },
  "scripts": {
    "start": "node src/server.js",
    "watch": "node src/watcher.js"
  },
  "keywords": [
    "ai",
    "token",
    "optimization",
    "llm",
    "context",
    "summarization",
    "openai",
    "tokens",
    "compression",
    "mcp",
    "model-context-protocol",
    "claude",
    "anthropic",
    "cursor",
    "ai-tools",
    "token-reduction",
    "context-compression"
  ],
  "author": "Corby Bender",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/corbybender/token-shrinker.git"
  },
  "bugs": {
    "url": "https://github.com/corbybender/token-shrinker/issues"
  },
  "homepage": "https://github.com/corbybender/token-shrinker#readme",
  "engines": {
    "node": ">=18.0.0"
  },
  "files": [
    "src/*.js",
    "!src/test.js",
    "bin/**/*",
    "readme.md",
    "PROXY_SETUP.md",
    "LICENSE",
    ".env.example"
  ],
  "dependencies": {
    "@anthropic-ai/sdk": "^0.20.0",
    "body-parser": "^1.20.2",
    "chokidar": "^3.5.3",
    "dotenv": "^16.0.0",
    "esprima": "^4.0.1",
    "express": "^4.18.2",
    "fs-extra": "^11.1.1",
    "openai": "^4.5.0"
  }
}
