{
  "name": "ai-token-optimizer",
  "version": "0.3.73",
  "description": "Model Context Protocol (MCP) server that provides AI context compression tools. Reduces token usage by intelligently summarizing text, files, and repositories. Compatible with Claude Desktop, Cursor, and other MCP clients. Also works as transparent proxy for OpenRouter and Anthropic APIs.",
  "type": "module",
  "main": "src/server.js",
  "bin": {
    "ai-token-optimizer": "./bin/cli.js"
  },
  "scripts": {
    "start": "node src/server.js",
    "watch": "node src/watcher.js"
  },
  "keywords": [
    "ai",
    "token",
    "optimization",
    "llm",
    "context",
    "summarization",
    "openai",
    "tokens",
    "compression",
    "mcp",
    "model-context-protocol",
    "claude",
    "anthropic",
    "cursor",
    "ai-tools",
    "token-reduction",
    "context-compression"
  ],
  "author": "Corby Bender",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/corbybender/ai-token-optimizer.git"
  },
  "bugs": {
    "url": "https://github.com/corbybender/ai-token-optimizer/issues"
  },
  "homepage": "https://github.com/corbybender/ai-token-optimizer#readme",
  "engines": {
    "node": ">=18.0.0"
  },
  "files": [
    "src/*.js",
    "!src/test.js",
    "bin/**/*",
    "readme.md",
    "PROXY_SETUP.md",
    "LICENSE",
    ".env.example"
  ],
  "dependencies": {
    "@anthropic-ai/sdk": "^0.20.0",
    "body-parser": "^1.20.2",
    "chokidar": "^3.5.3",
    "dotenv": "^16.0.0",
    "esprima": "^4.0.1",
    "express": "^4.18.2",
    "fs-extra": "^11.1.1",
    "openai": "^4.5.0"
  }
}
